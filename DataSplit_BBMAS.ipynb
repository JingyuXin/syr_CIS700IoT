{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "path = '/home/jxin05/Dataset/BB-MAS_Dataset/BB-MAS_Dataset/'\n",
    "outpath = '/home/jxin05/BBMAS_Data/'\n",
    "rawpath = '/home/jxin05/BBMAS_Data/rawdata/'\n",
    "fixlen_path = '/home/jxin05/BBMAS_Data/fixlen_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_list = [str(i) for i in range(1,118)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_checkpoint(path): \n",
    "    files = os.listdir(path)\n",
    "    check1_exist = False\n",
    "    check2_exist = False\n",
    "    acc_data_exist = False\n",
    "    check_sess1 = None\n",
    "    check_sess2 = None\n",
    "    acc_data = None\n",
    "    for file in files:\n",
    "        if(fnmatch.fnmatch(file, '*_HandPhone_Checkpoints_*')):\n",
    "            check_sess1 = pd.read_csv(os.path.join(path + file))\n",
    "            check1_exist = True\n",
    "            #print(\"session 1 found for \" + path)\n",
    "        if(fnmatch.fnmatch(file, '*_HandTablet_Checkpoints_*')):\n",
    "            check_sess2 = pd.read_csv(os.path.join(path + file))\n",
    "            check2_exist = True\n",
    "            #print(\"session 2 found for \" + path)\n",
    "        if(fnmatch.fnmatch(file, '*_PocketPhone_Accelerometer_*')):\n",
    "            acc_data = pd.read_csv(os.path.join(path + file))\n",
    "            acc_data_exist = True\n",
    "            #print(\"acc data found for \" + path)\n",
    "    return check1_exist, check2_exist, acc_data_exist, check_sess1, check_sess2, acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_valid(user_list, path):\n",
    "    valid_user = []\n",
    "    user_dict = {}\n",
    "    for user in user_list:\n",
    "        if user not in user_dict:\n",
    "            user_dict[int(user)] = {}\n",
    "        check1_exist, check2_exist, acc_data_exist, check_sess1, check_sess2, acc_data = find_checkpoint(path+user+'/')\n",
    "        if(check1_exist and check2_exist and acc_data_exist):\n",
    "            valid_user.append(user)\n",
    "            user_dict[int(user)]['check1'] = check_sess1\n",
    "            user_dict[int(user)]['check2'] = check_sess2\n",
    "            user_dict[int(user)]['acc_data'] = acc_data\n",
    "    return valid_user, user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_user, user_dict = check_valid(user_list, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_start_end(check_sess1, check_sess2):\n",
    "    start1, start2, end1, end2 = 0,0,0,0\n",
    "    for idx in range(len(check_sess1)):\n",
    "        row = check_sess1.iloc[idx]\n",
    "        if(row['EID'] == 1):\n",
    "            start1 = row['time']\n",
    "        if(row['EID'] == 14):\n",
    "            end1 = row['time']\n",
    "    for idx in range(len(check_sess2)):\n",
    "        row = check_sess2.iloc[idx]\n",
    "        if(row['EID'] == 1):\n",
    "            start2 = row['time']\n",
    "        if(row['EID'] == 14):\n",
    "            end2 = row['time']\n",
    "    if(start1 == 0 or end1 == 0):\n",
    "        print(\"incomplete data ins session 1\")\n",
    "    if(start2 == 0 or end2 == 0):\n",
    "        print(\"incomplete data ins session 2\")\n",
    "    return start1,end1,start2, end2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_time_col(df):\n",
    "    df['time_in_ms'] = df['time'].apply(make_time)\n",
    "    return df\n",
    "def make_time(timestamp):\n",
    "    return time.mktime(time.strptime(timestamp[:-4],'%Y-%m-%d %H:%M:%S')) +float('0'+timestamp[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_index(df, start1, end1, start2, end2):\n",
    "    if(start1 == 0 or end1 == 0 or start2 == 0 or end2 == 0):\n",
    "        print('some data is missing, do not use this user')\n",
    "        return\n",
    "    start1 = make_time(start1)\n",
    "    start2 = make_time(start2)\n",
    "    end1 = make_time(end1)\n",
    "    end2 = make_time(end2)\n",
    "    df = make_time_col(df)\n",
    "    start_idx1, start_idx2, end_idx1, end_idx2 = -1,-1,-1,-1\n",
    "    for idx in range(len(df)):\n",
    "        row = df.iloc[idx]\n",
    "        if(row['time_in_ms'] >= start1 and row['time_in_ms'] - start1 <= 5):\n",
    "            start_idx1 = idx\n",
    "        if(row['time_in_ms'] >= start2 and row['time_in_ms'] - start2 <= 5):\n",
    "            start_idx2 = idx\n",
    "        if(row['time_in_ms'] <= end1 and end1 - row['time_in_ms'] <= 5):\n",
    "            end_idx1 = idx\n",
    "        if(row['time_in_ms'] <= end2 and end2 - row['time_in_ms'] <= 5):\n",
    "            end_idx2 = idx\n",
    "    if(start_idx1 > 0 and end_idx1 > 0 and start_idx2 > 0 and end_idx2 > 0):\n",
    "        return start_idx1, end_idx1, start_idx2, end_idx2\n",
    "    else:\n",
    "        print('did not find correct index')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_session(outpath, user_dict):\n",
    "    for user in user_dict.keys():\n",
    "        if(user_dict[user] == {}):\n",
    "            continue\n",
    "        print(\"processing data from user\" + str(user))\n",
    "        start1,end1,start2, end2 = get_start_end(user_dict[user]['check1'], user_dict[user]['check2'])\n",
    "        if(start1 == 0 or end1 == 0 or start2 == 0 or end2 == 0):\n",
    "            print('user' + str(user) + \" has missing data\")\n",
    "            continue\n",
    "        try:\n",
    "            start_idx1, end_idx1, start_idx2, end_idx2 = find_index(user_dict[user]['acc_data'], start1,end1,start2, end2)\n",
    "        except:\n",
    "            print('stop using user ' + str(user))\n",
    "            continue\n",
    "        sess1 = user_dict[user]['acc_data'].iloc[start_idx1:end_idx1+1]\n",
    "        sess2 = user_dict[user]['acc_data'].iloc[start_idx2:end_idx2+1]\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        sess1.to_csv(outpath + str(user) + 'session1.csv',index=False)\n",
    "        sess2.to_csv(outpath + str(user) + 'session2.csv',index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data from user10\n",
      "processing data from user11\n",
      "processing data from user13\n",
      "processing data from user15\n",
      "processing data from user16\n",
      "processing data from user17\n",
      "processing data from user18\n",
      "processing data from user19\n"
     ]
    }
   ],
   "source": [
    "split_session(rawpath, user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_col(df):\n",
    "    return df.drop(['EID','time','time_in_ms'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_len(length, outpath,inpath = rawpath):\n",
    "    files = os.listdir(inpath)\n",
    "    for file in files:\n",
    "        df = pd.read_csv(inpath + file)\n",
    "        if len(df) <= length:\n",
    "            continue\n",
    "        diff = int((len(df) - length)/2)\n",
    "        processed = df.iloc[diff:diff+length]\n",
    "        processed.to_csv(outpath+file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix_len(12000, fixlen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mix_data(truepath, fake_number, replace_time, replace_size = 200):\n",
    "    file_list = os.listdir(truepath)\n",
    "    pick_dict = {}\n",
    "    mixed_data = []\n",
    "    count = 0\n",
    "    \n",
    "    while(count < fake_number):\n",
    "        pick = np.random.randint(0,len(file_list))\n",
    "        pick_dict[count] = []\n",
    "        print(\"creating fake sample from \" + file_list[pick])\n",
    "        target = pd.read_csv(truepath + file_list[pick])\n",
    "        mix = np.asarray(remove_col(target).values)\n",
    "        for j in range(replace_time): \n",
    "            start = np.random.randint(3,len(target)/replace_size-1)\n",
    "            while(start in pick_dict[count]):\n",
    "                start = np.random.randint(3,len(target)/replace_size-1)\n",
    "            pick_dict[count].append(start)\n",
    "            replace_clip = take_from_others(truepath, replace_size, pick, file_list)\n",
    "            mix[start*replace_size:(start+1)*replace_size, :] = replace_clip\n",
    "        mixed_data.append(mix)\n",
    "        print(\"clips replaced: {}\".format(np.sort(pick_dict[count])))\n",
    "        count+=1\n",
    "        print(\"**********\")\n",
    "    return mixed_data, pick_dict           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_from_others(truepath, replace_size, pick, file_list):\n",
    "    takefrom = np.random.randint(0,len(file_list))\n",
    "    while(takefrom == pick):\n",
    "        takefrom = np.random.randint(0,len(file_list))\n",
    "    target_df = pd.read_csv(truepath+file_list[takefrom])\n",
    "    start_idx = np.random.randint(0,len(target_df)-replace_size)\n",
    "    replace_clip = target_df.iloc[start_idx:start_idx+replace_size]\n",
    "    replace_clip = remove_col(replace_clip)\n",
    "    return np.asarray(replace_clip.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating fake sample from 34session1.csv\n",
      "clips replaced: [11 20 24 27 33 35 41 46 49 50]\n",
      "**********\n",
      "creating fake sample from 27session1.csv\n",
      "clips replaced: [ 5 14 21 28 29 35 37 43 49 53]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "mixed_data1, pick_dict1 = mix_data(fixlen_path, 2, 10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth(mixed_data, pick_dict, window = 3):\n",
    "    res = mixed_data.copy()\n",
    "    for i in range(len(mixed_data)):\n",
    "        for v in pick_dict[i]:\n",
    "            #print(v)\n",
    "            start = v*200-10\n",
    "            end = v*200+10\n",
    "            data_x = mixed_data[i][start:end,0].copy()\n",
    "            #print(data_x)\n",
    "            data_y = mixed_data[i][start:end,1].copy()\n",
    "            data_z = mixed_data[i][start:end,2].copy()\n",
    "            smoothed_x = ExpMovingAverage(data_x, window)\n",
    "            #print(smoothed_x)\n",
    "            smoothed_y = ExpMovingAverage(data_y, window)\n",
    "            smoothed_z = ExpMovingAverage(data_z, window)\n",
    "            res[i][start+window+1:end-window,0] = smoothed_x[window+1:-window]\n",
    "            #print(res[i][start+window+1:end-window,0])\n",
    "            res[i][start+window+1:end-window,1] = smoothed_y[window+1:-window]\n",
    "            res[i][start+window+1:end-window,2] = smoothed_z[window+1:-window]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExpMovingAverage(array, window):\n",
    "    weights = np.exp(np.linspace(-1., 0., window))\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    a = np.convolve(array, weights, mode='full')[:len(array)]\n",
    "    a[:window] = a[window]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fake_dataset(mixed_data, pick_dict):\n",
    "    sample_len = mixed_data[0].shape[0]\n",
    "    num_sample = len(mixed_data)\n",
    "    X = np.zeros((num_sample, mixed_data[0].shape[1], sample_len))\n",
    "    Y = np.zeros((num_sample, 60))\n",
    "    for i in range(len(mixed_data)):\n",
    "        X[i,:,:] = mixed_data[i].T\n",
    "        for v in pick_dict[i]:\n",
    "            Y[i,v] = 1\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = make_fake_dataset(mixed_data1, pick_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
